{
  "$schema": "https://ui.shadcn.com/schema/registry-item.json",
  "name": "use-scribe",
  "type": "registry:hook",
  "dependencies": [
    "@elevenlabs/react"
  ],
  "files": [
    {
      "path": "hooks/use-scribe.ts",
      "content": "\"use client\"\n\nimport { useCallback, useRef, useState } from \"react\"\n\nexport enum AudioFormat {\n  PCM_8000 = \"pcm_8000\",\n  PCM_16000 = \"pcm_16000\",\n  PCM_22050 = \"pcm_22050\",\n  PCM_24000 = \"pcm_24000\",\n  PCM_44100 = \"pcm_44100\",\n  PCM_48000 = \"pcm_48000\",\n  ULAW_8000 = \"ulaw_8000\",\n}\n\nexport enum CommitStrategy {\n  MANUAL = \"manual\",\n  VAD = \"vad\",\n}\n\nexport interface CommittedTranscript {\n  text: string\n}\n\nexport interface UseScribeOptions {\n  modelId?: string\n  baseUri?: string\n  commitStrategy?: CommitStrategy\n  vadSilenceThresholdSecs?: number\n  vadThreshold?: number\n  minSpeechDurationMs?: number\n  minSilenceDurationMs?: number\n  languageCode?: string\n  audioFormat?: AudioFormat\n  sampleRate?: number\n  microphone?: {\n    deviceId?: string\n    echoCancellation?: boolean\n    noiseSuppression?: boolean\n    autoGainControl?: boolean\n    channelCount?: number\n  }\n  onPartialTranscript?: (data: { text: string }) => void\n  onCommittedTranscript?: (data: { text: string }) => void\n  onError?: (error: Error | Event) => void\n  onAuthError?: (data: { error: string }) => void\n  onQuotaExceededError?: (data: { error: string }) => void\n}\n\nexport interface UseScribeReturn {\n  status: \"disconnected\" | \"connecting\" | \"connected\"\n  isConnected: boolean\n  error: string | null\n  partialTranscript: string\n  committedTranscripts: CommittedTranscript[]\n  connect: (options: { token: string }) => Promise<void>\n  disconnect: () => void\n  clearTranscripts: () => void\n}\n\ninterface ScribeConnection {\n  close: () => void\n}\n\nconst AUDIO_FORMAT_SAMPLE_RATES: Record<AudioFormat, number> = {\n  [AudioFormat.PCM_8000]: 8000,\n  [AudioFormat.PCM_16000]: 16000,\n  [AudioFormat.PCM_22050]: 22050,\n  [AudioFormat.PCM_24000]: 24000,\n  [AudioFormat.PCM_44100]: 44100,\n  [AudioFormat.PCM_48000]: 48000,\n  [AudioFormat.ULAW_8000]: 8000,\n}\n\n/**\n * A hook for real-time speech-to-text transcription using ElevenLabs Scribe.\n *\n * This hook wraps the ScribeRealtime class from @elevenlabs/react and provides\n * a React-friendly interface for managing transcription state.\n */\nexport function useScribe(options: UseScribeOptions): UseScribeReturn {\n  const {\n    modelId = \"scribe_v2_realtime\",\n    baseUri,\n    commitStrategy = CommitStrategy.VAD,\n    vadSilenceThresholdSecs,\n    vadThreshold,\n    minSpeechDurationMs,\n    minSilenceDurationMs,\n    languageCode,\n    audioFormat,\n    sampleRate,\n    microphone,\n    onPartialTranscript,\n    onCommittedTranscript,\n    onError,\n    onAuthError,\n    onQuotaExceededError,\n  } = options\n\n  const [status, setStatus] = useState<\n    \"disconnected\" | \"connecting\" | \"connected\"\n  >(\"disconnected\")\n  const [error, setError] = useState<string | null>(null)\n  const [partialTranscript, setPartialTranscript] = useState(\"\")\n  const [committedTranscripts, setCommittedTranscripts] = useState<\n    CommittedTranscript[]\n  >([])\n\n  const connectionRef = useRef<ScribeConnection | null>(null)\n  const mediaStreamRef = useRef<MediaStream | null>(null)\n  const audioContextRef = useRef<AudioContext | null>(null)\n  const workletNodeRef = useRef<AudioWorkletNode | null>(null)\n\n  const clearTranscripts = useCallback(() => {\n    setPartialTranscript(\"\")\n    setCommittedTranscripts([])\n    setError(null)\n  }, [])\n\n  const disconnect = useCallback(() => {\n    // Stop audio worklet\n    if (workletNodeRef.current) {\n      workletNodeRef.current.disconnect()\n      workletNodeRef.current = null\n    }\n\n    // Close audio context\n    if (audioContextRef.current) {\n      audioContextRef.current.close().catch(() => {})\n      audioContextRef.current = null\n    }\n\n    // Stop media stream\n    if (mediaStreamRef.current) {\n      mediaStreamRef.current.getTracks().forEach((track) => track.stop())\n      mediaStreamRef.current = null\n    }\n\n    // Close WebSocket connection\n    if (connectionRef.current) {\n      connectionRef.current.close()\n      connectionRef.current = null\n    }\n\n    setStatus(\"disconnected\")\n  }, [])\n\n  const connect = useCallback(\n    async ({ token }: { token: string }) => {\n      // Disconnect any existing connection\n      disconnect()\n\n      setStatus(\"connecting\")\n      setError(null)\n\n      try {\n        // Build WebSocket URL\n        const base = baseUri || \"wss://api.elevenlabs.io\"\n        const params = new URLSearchParams()\n        params.set(\"model_id\", modelId)\n        params.set(\"token\", token)\n\n        if (commitStrategy) {\n          params.set(\"commit_strategy\", commitStrategy)\n        }\n        if (vadSilenceThresholdSecs !== undefined) {\n          params.set(\n            \"vad_silence_threshold_secs\",\n            vadSilenceThresholdSecs.toString()\n          )\n        }\n        if (vadThreshold !== undefined) {\n          params.set(\"vad_threshold\", vadThreshold.toString())\n        }\n        if (minSpeechDurationMs !== undefined) {\n          params.set(\"min_speech_duration_ms\", minSpeechDurationMs.toString())\n        }\n        if (minSilenceDurationMs !== undefined) {\n          params.set(\"min_silence_duration_ms\", minSilenceDurationMs.toString())\n        }\n        if (languageCode) {\n          params.set(\"language_code\", languageCode)\n        }\n\n        const wsUrl = `${base}/v1/speech-to-text/realtime-beta?${params.toString()}`\n\n        // Create WebSocket connection\n        const ws = new WebSocket(wsUrl)\n\n        // Set up connection promise\n        const connectionPromise = new Promise<void>((resolve, reject) => {\n          let isSettled = false\n          const timeout = setTimeout(() => {\n            if (!isSettled) {\n              isSettled = true\n              reject(new Error(\"Connection timeout\"))\n            }\n          }, 30000)\n          const resolveOnce = () => {\n            if (isSettled) return\n            isSettled = true\n            clearTimeout(timeout)\n            resolve()\n          }\n          const rejectOnce = (error: Error) => {\n            if (isSettled) return\n            isSettled = true\n            clearTimeout(timeout)\n            reject(error)\n          }\n\n          ws.onmessage = (event) => {\n            try {\n              const data = JSON.parse(event.data)\n              const messageType = data.type || data.message_type\n\n              switch (messageType) {\n                case \"session_started\":\n                  setStatus(\"connected\")\n                  resolveOnce()\n                  break\n\n                case \"auth_error\":\n                  setError(data.error || \"Authentication failed\")\n                  onAuthError?.({\n                    error: data.error || \"Authentication failed\",\n                  })\n                  rejectOnce(new Error(data.error || \"Authentication failed\"))\n                  break\n\n                case \"quota_exceeded\":\n                  setError(data.error || \"Quota exceeded\")\n                  onQuotaExceededError?.({\n                    error: data.error || \"Quota exceeded\",\n                  })\n                  rejectOnce(new Error(data.error || \"Quota exceeded\"))\n                  break\n\n                case \"partial_transcript\":\n                  setPartialTranscript(data.text || \"\")\n                  onPartialTranscript?.({ text: data.text || \"\" })\n                  break\n\n                case \"final_transcript\":\n                case \"final_transcript_with_timestamps\":\n                  setCommittedTranscripts((prev) => [\n                    ...prev,\n                    { text: data.text || \"\" },\n                  ])\n                  setPartialTranscript(\"\")\n                  onCommittedTranscript?.({ text: data.text || \"\" })\n                  break\n\n                case \"error\":\n                  {\n                    const errorMessage = data.error || \"Unknown error\"\n                    const error = new Error(errorMessage)\n                    setError(errorMessage)\n                    onError?.(error)\n                    rejectOnce(error)\n                  }\n                  break\n              }\n            } catch {\n              // Ignore JSON parse errors\n            }\n          }\n\n          ws.onerror = (event) => {\n            setError(\"WebSocket error\")\n            onError?.(event)\n            rejectOnce(new Error(\"WebSocket error\"))\n          }\n\n          ws.onclose = () => {\n            setStatus(\"disconnected\")\n            if (!isSettled) {\n              rejectOnce(new Error(\"WebSocket closed before session started\"))\n            }\n          }\n        })\n\n        connectionRef.current = { close: () => ws.close() }\n\n        // Wait for authentication\n        await connectionPromise\n\n        // Get microphone stream\n        const micConfig = microphone || {}\n        const stream = await navigator.mediaDevices.getUserMedia({\n          audio: {\n            deviceId: micConfig.deviceId,\n            echoCancellation: micConfig.echoCancellation ?? true,\n            noiseSuppression: micConfig.noiseSuppression ?? true,\n            autoGainControl: micConfig.autoGainControl,\n            channelCount: micConfig.channelCount || 1,\n          },\n        })\n        mediaStreamRef.current = stream\n\n        // Set up audio processing\n        const targetSampleRate =\n          sampleRate ||\n          (audioFormat ? AUDIO_FORMAT_SAMPLE_RATES[audioFormat] : undefined) ||\n          16000\n\n        const audioContext = new AudioContext({\n          sampleRate: targetSampleRate,\n        })\n        audioContextRef.current = audioContext\n\n        const source = audioContext.createMediaStreamSource(stream)\n\n        // Create script processor for audio data\n        const bufferSize = 4096\n        const processor = audioContext.createScriptProcessor(bufferSize, 1, 1)\n\n        processor.onaudioprocess = (e) => {\n          if (ws.readyState !== WebSocket.OPEN) return\n\n          const inputData = e.inputBuffer.getChannelData(0)\n\n          // Convert Float32 to Int16\n          const int16Data = new Int16Array(inputData.length)\n          for (let i = 0; i < inputData.length; i++) {\n            const s = Math.max(-1, Math.min(1, inputData[i]))\n            int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7fff\n          }\n\n          // Send audio data as base64\n          const uint8Array = new Uint8Array(int16Data.buffer)\n          const base64 = btoa(String.fromCharCode(...uint8Array))\n\n          ws.send(\n            JSON.stringify({\n              message_type: \"input_audio_chunk\",\n              audio_base_64: base64,\n              sample_rate: audioContext.sampleRate,\n              commit: false,\n            })\n          )\n        }\n\n        source.connect(processor)\n        processor.connect(audioContext.destination)\n      } catch (err) {\n        setStatus(\"disconnected\")\n        const message = err instanceof Error ? err.message : \"Connection failed\"\n        setError(message)\n        onError?.(err instanceof Error ? err : new Error(message))\n        throw err\n      }\n    },\n    [\n      baseUri,\n      modelId,\n      commitStrategy,\n      vadSilenceThresholdSecs,\n      vadThreshold,\n      minSpeechDurationMs,\n      minSilenceDurationMs,\n      languageCode,\n      audioFormat,\n      sampleRate,\n      microphone,\n      onPartialTranscript,\n      onCommittedTranscript,\n      onError,\n      onAuthError,\n      onQuotaExceededError,\n      disconnect,\n    ]\n  )\n\n  return {\n    status,\n    isConnected: status === \"connected\",\n    error,\n    partialTranscript,\n    committedTranscripts,\n    connect,\n    disconnect,\n    clearTranscripts,\n  }\n}\n",
      "type": "registry:hook"
    }
  ]
}